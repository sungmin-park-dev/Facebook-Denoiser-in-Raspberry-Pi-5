#!/usr/bin/env python3
"""
Real-time Audio Denoising - Buffered Streaming with Original Denoiser Models
Smooth continuous output with acceptable latency
"""

import sounddevice as sd
import torch
import numpy as np
import time
from scipy import signal
import warnings
import os
from collections import deque
import threading
import queue

os.environ['PYTHONWARNINGS'] = 'ignore'
warnings.filterwarnings('ignore')

# ========== Configuration ==========
HARDWARE_SR = 48000
MODEL_SR = 16000
CHUNK = 16000  # 333ms @ 48kHz (ì²˜ë¦¬ ë‹¨ìœ„)
INPUT_DEVICE = 1   # H08A Audio: USB Audio (hw:1,0)
OUTPUT_DEVICE = 1  # H08A Audio: USB Audio (hw:1,0)

# ì›ë³¸ denoiser ëª¨ë¸ ì„ íƒ (í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”)
MODEL_NAME = 'dns48'      # ê°€ì¥ ê°€ë²¼ìš´ ëª¨ë¸ (~2.5M params) â­ RP5 ì¶”ì²œ
# MODEL_NAME = 'dns64'      # ì¤‘ê°„ ëª¨ë¸ (~5.5M params) - RTF 1.9 (ë„ˆë¬´ ëŠë¦¼)
# MODEL_NAME = 'master64'   # ê°€ì¥ ë¬´ê±°ìš´ ëª¨ë¸ (~14M params)

# ë²„í¼ ì„¤ì •
BUFFER_SIZE = 96000  # 2ì´ˆ ë²„í¼ (ë¶€ë“œëŸ¬ìš´ ì¶œë ¥)
output_buffer = deque(maxlen=BUFFER_SIZE)
buffer_lock = threading.Lock()

# ì²˜ë¦¬ í
process_queue = queue.Queue(maxsize=10)

# ========== Model Loading ==========
print("=" * 60)
print(f"ğŸ“¦ Loading original denoiser model: {MODEL_NAME}")
print("=" * 60)

try:
    # torch.hubë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ ëª¨ë¸ ë¡œë“œ
    torch.hub.set_dir('/home/test1/.cache/torch/hub')
    model = torch.hub.load('facebookresearch/denoiser', MODEL_NAME, force_reload=False)
    model.eval()
    
    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    total_params = sum(p.numel() for p in model.parameters())
    print(f"âœ… Model loaded successfully!")
    print(f"   Parameters: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"   Model: {MODEL_NAME}")
    
    # JIT ì»´íŒŒì¼ (ì„±ëŠ¥ í–¥ìƒ)
    print("\nğŸ”§ Compiling model with TorchScript...")
    dummy_input = torch.randn(1, 1, CHUNK // 3)
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        model = torch.jit.trace(model, dummy_input)
    print("âœ… Model compiled\n")
    
except Exception as e:
    print(f"âŒ Failed to load model: {e}")
    print("\nğŸ’¡ Troubleshooting:")
    print("   1. Check internet connection (first download)")
    print("   2. Try: pip install soundfile")
    print("   3. Clear cache: rm -rf ~/.cache/torch/hub")
    exit(1)

# ========== Stats ==========
chunk_count = 0
rtf_list = []
start_time = time.time()
processing = True

# ========== Processing Thread ==========
def processing_thread():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì˜¤ë””ì˜¤ ì²˜ë¦¬"""
    global chunk_count
    
    while processing:
        try:
            audio_data = process_queue.get(timeout=0.1)
            
            t0 = time.time()
            
            # Downsample: 48k â†’ 16k
            audio_16k = signal.resample_poly(audio_data, 1, 3)
            
            # Model inference
            x = torch.from_numpy(audio_16k).float().unsqueeze(0).unsqueeze(0)
            with torch.no_grad():
                y = model(x)
            
            # Upsample: 16k â†’ 48k
            denoised = signal.resample_poly(y.squeeze().cpu().numpy(), 3, 1)
            
            # ë²„í¼ì— ì¶”ê°€
            with buffer_lock:
                for sample in denoised:
                    if len(output_buffer) < BUFFER_SIZE:
                        output_buffer.append(sample)
            
            # Stats
            process_time = time.time() - t0
            rtf = process_time / (len(audio_16k) / MODEL_SR)
            rtf_list.append(rtf)
            chunk_count += 1
            
            if chunk_count % 30 == 0:
                elapsed = time.time() - start_time
                avg_rtf = np.mean(rtf_list[-30:])
                buffer_ms = len(output_buffer) / HARDWARE_SR * 1000
                print(f"[{elapsed:5.1f}s] Chunks: {chunk_count:3d} | RTF: {avg_rtf:.3f} | Buffer: {buffer_ms:.0f}ms")
            
        except queue.Empty:
            continue
        except Exception as e:
            print(f"âŒ Processing error: {e}")

# ========== Input Callback ==========
def input_callback(indata, frames, time_info, status):
    """ë§ˆì´í¬ ì…ë ¥ â†’ ì²˜ë¦¬ íì— ì¶”ê°€"""
    if status:
        print(f"âš ï¸  Input: {status}")
    
    try:
        # ìŠ¤í…Œë ˆì˜¤ â†’ ëª¨ë…¸ ë³€í™˜ (í‰ê· )
        if indata.shape[1] == 2:
            audio_data = np.mean(indata, axis=1)
        else:
            audio_data = indata[:, 0].copy()
        
        # ë…¼ë¸”ë¡œí‚¹ìœ¼ë¡œ íì— ì¶”ê°€
        process_queue.put_nowait(audio_data)
    except queue.Full:
        pass  # íê°€ ê°€ë“ ì°¨ë©´ ìŠ¤í‚µ

# ========== Output Callback ==========
def output_callback(outdata, frames, time_info, status):
    """ë²„í¼ì—ì„œ êº¼ë‚´ì„œ ìŠ¤í”¼ì»¤ë¡œ ì¶œë ¥"""
    if status:
        print(f"âš ï¸  Output: {status}")
    
    with buffer_lock:
        for i in range(frames):
            if output_buffer:
                outdata[i, 0] = output_buffer.popleft()
            else:
                outdata[i, 0] = 0  # ë²„í¼ ë¹„ì—ˆìœ¼ë©´ ë¬´ìŒ

# ========== Main ==========
def main():
    global processing
    
    print("=" * 60)
    print(f"ğŸ¤ Input: Device {INPUT_DEVICE}")
    print(f"ğŸ”Š Output: Device {OUTPUT_DEVICE}")
    print(f"ğŸ“¦ Processing chunk: {CHUNK/HARDWARE_SR*1000:.0f}ms")
    print(f"ğŸ”„ Output buffer: {BUFFER_SIZE/HARDWARE_SR*1000:.0f}ms")
    print(f"â±ï¸  Initial latency: ~2 seconds (buffer fill)")
    print("=" * 60)
    print(f"\nğŸš€ Starting buffered streaming with {MODEL_NAME}...")
    print("   ğŸ¤ Speak continuously - output will be smooth!")
    print("   â³ Wait 2-3 seconds for buffer to fill...")
    print("   Press Ctrl+C to stop\n")

    # ì²˜ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘
    proc_thread = threading.Thread(target=processing_thread, daemon=True)
    proc_thread.start()

    try:
        # ì…ë ¥ ìŠ¤íŠ¸ë¦¼ (ìŠ¤í…Œë ˆì˜¤)
        input_stream = sd.InputStream(
            samplerate=HARDWARE_SR,
            blocksize=CHUNK,
            device=INPUT_DEVICE,
            channels=2,  # H08AëŠ” ìŠ¤í…Œë ˆì˜¤
            dtype=np.float32,
            callback=input_callback
        )
        
        # ì¶œë ¥ ìŠ¤íŠ¸ë¦¼
        output_stream = sd.OutputStream(
            samplerate=HARDWARE_SR,
            blocksize=1024,  # ì‘ì€ ì²­í¬ë¡œ ë¶€ë“œëŸ¬ìš´ ì¶œë ¥
            device=OUTPUT_DEVICE,
            channels=1,
            dtype=np.float32,
            callback=output_callback
        )
        
        with input_stream, output_stream:
            while True:
                sd.sleep(1000)
            
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ Stopping...")
        processing = False
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        processing = False

    # Final stats
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Final Stats ({MODEL_NAME}):")
    print(f"   Chunks processed: {chunk_count}")
    print(f"   Runtime: {time.time() - start_time:.1f}s")
    
    if len(rtf_list) > 5:
        stable_rtf = rtf_list[5:]
        print(f"   Avg RTF: {np.mean(stable_rtf):.3f}")
        print(f"   Max RTF: {np.max(stable_rtf):.3f}")
        print(f"   Min RTF: {np.min(stable_rtf):.3f}")
    
    print(f"{'='*60}\n")

if __name__ == "__main__":
    main()