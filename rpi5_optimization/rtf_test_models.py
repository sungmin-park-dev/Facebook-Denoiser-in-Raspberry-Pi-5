#!/usr/bin/env python3
"""
ë¼ì¦ˆë² ë¦¬íŒŒì´ 5ìš© RTF ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬ì„±ìœ¼ë¡œ RTFë¥¼ ì¸¡ì •í•˜ì—¬ ìµœì  ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤.
"""

import torch
import time
import sys
import os
from pathlib import Path

# denoiser ëª¨ë“ˆ import
sys.path.append('/home/test1/denoiser')
from denoiser.demucs import Demucs, DemucsStreamer

def test_model_rtf(model_config, num_tests=5, audio_duration=4.0):
    """
    ì£¼ì–´ì§„ ëª¨ë¸ êµ¬ì„±ìœ¼ë¡œ RTFë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
    
    Args:
        model_config (dict): ëª¨ë¸ ì„¤ì •
        num_tests (int): í…ŒìŠ¤íŠ¸ ë°˜ë³µ íšŸìˆ˜
        audio_duration (float): í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ)
    
    Returns:
        dict: RTF ê²°ê³¼ ë° ëª¨ë¸ ì •ë³´
    """
    sample_rate = 16000
    device = 'cpu'  # ë¼ì¦ˆë² ë¦¬íŒŒì´ëŠ” CPUë§Œ ì‚¬ìš©
    
    try:
        # ëª¨ë¸ ìƒì„±
        model = Demucs(**model_config, sample_rate=sample_rate)
        model.eval()
        model_size_mb = sum(p.numel() for p in model.parameters()) * 4 / 2**20
        
        # ìŠ¤íŠ¸ë¦¬ë¨¸ ìƒì„±
        streamer = DemucsStreamer(model, num_frames=1)
        
        # í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„±
        audio_length = int(sample_rate * audio_duration)
        test_audio = torch.randn(1, audio_length)
        
        rtf_results = []
        
        # RTF ì¸¡ì •
        for test_idx in range(num_tests):
            streamer.reset_time_per_frame()
            
            # í”„ë ˆìž„ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            frame_size = streamer.total_length
            audio_copy = test_audio.clone()
            
            with torch.no_grad():
                start_time = time.time()
                
                # ì²« ë²ˆì§¸ í”„ë ˆìž„
                if audio_copy.shape[1] >= frame_size:
                    streamer.feed(audio_copy[:, :frame_size])
                    audio_copy = audio_copy[:, frame_size:]
                    frame_size = streamer.stride
                
                # ë‚˜ë¨¸ì§€ í”„ë ˆìž„ë“¤
                while audio_copy.shape[1] > 0:
                    current_frame_size = min(frame_size, audio_copy.shape[1])
                    if current_frame_size > 0:
                        frame = audio_copy[:, :current_frame_size]
                        if current_frame_size < frame_size:
                            # íŒ¨ë”©
                            frame = torch.cat([frame, torch.zeros(1, frame_size - current_frame_size)], dim=1)
                        streamer.feed(frame)
                    audio_copy = audio_copy[:, current_frame_size:]
                
                # ë§ˆì§€ë§‰ ì²˜ë¦¬
                streamer.flush()
                end_time = time.time()
            
            processing_time = end_time - start_time
            rtf = processing_time / audio_duration
            rtf_results.append(rtf)
        
        # í†µê³„ ê³„ì‚°
        avg_rtf = sum(rtf_results) / len(rtf_results)
        min_rtf = min(rtf_results)
        max_rtf = max(rtf_results)
        
        return {
            'config': model_config,
            'model_size_mb': model_size_mb,
            'avg_rtf': avg_rtf,
            'min_rtf': min_rtf,
            'max_rtf': max_rtf,
            'rtf_results': rtf_results,
            'success': True,
            'error': None
        }
        
    except Exception as e:
        return {
            'config': model_config,
            'model_size_mb': 0,
            'avg_rtf': float('inf'),
            'min_rtf': float('inf'),
            'max_rtf': float('inf'),
            'rtf_results': [],
            'success': False,
            'error': str(e)
        }

def main():
    """ë¼ì¦ˆë² ë¦¬íŒŒì´ 5ìš© ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    print("=" * 80)
    print("ë¼ì¦ˆë² ë¦¬íŒŒì´ 5ìš© ì‹¤ì‹œê°„ ìŒì„± ë””ë…¸ì´ì§• ëª¨ë¸ RTF í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print(f"PyTorch ë²„ì „: {torch.__version__}")
    print(f"CPU ìŠ¤ë ˆë“œ ìˆ˜: {torch.get_num_threads()}")
    print()
    
    # í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ êµ¬ì„±ë“¤ (ì„±ëŠ¥ ìš°ì„ ìˆœìœ„ ìˆœì„œ)
    model_configs = [
        # 1. ìµœê²½ëŸ‰ ëª¨ë¸ë“¤ (RTF < 0.5 ëª©í‘œ)
        {
            'name': 'Ultra-Light-24',
            'chin': 1, 'chout': 1, 'hidden': 24, 'depth': 3,
            'kernel_size': 8, 'stride': 4, 'causal': True,
            'resample': 2, 'growth': 1.5, 'max_hidden': 96,
            'normalize': True, 'glu': False, 'rescale': 0.1
        },
        {
            'name': 'Ultra-Light-32',
            'chin': 1, 'chout': 1, 'hidden': 32, 'depth': 3,
            'kernel_size': 8, 'stride': 4, 'causal': True,
            'resample': 2, 'growth': 1.5, 'max_hidden': 128,
            'normalize': True, 'glu': False, 'rescale': 0.1
        },
        
        # 2. ê²½ëŸ‰ ëª¨ë¸ë“¤ (RTF < 0.8 ëª©í‘œ)
        {
            'name': 'Light-32-Depth4',
            'chin': 1, 'chout': 1, 'hidden': 32, 'depth': 4,
            'kernel_size': 8, 'stride': 4, 'causal': True,
            'resample': 2, 'growth': 1.5, 'max_hidden': 128,
            'normalize': True, 'glu': False, 'rescale': 0.1
        },
        {
            'name': 'Light-40',
            'chin': 1, 'chout': 1, 'hidden': 40, 'depth': 4,
            'kernel_size': 8, 'stride': 4, 'causal': True,
            'resample': 2, 'growth': 1.5, 'max_hidden': 160,
            'normalize': True, 'glu': False, 'rescale': 0.1
        },
        
        # 3. ê¸°ë³¸ ê²½ëŸ‰ ëª¨ë¸ë“¤ (RTF < 1.0 ëª©í‘œ)
        {
            'name': 'Standard-Light-48',
            'chin': 1, 'chout': 1, 'hidden': 48, 'depth': 4,
            'kernel_size': 8, 'stride': 4, 'causal': True,
            'resample': 2, 'growth': 1.5, 'max_hidden': 192,
            'normalize': True, 'glu': False, 'rescale': 0.1
        },
        {
            'name': 'Standard-48-Resample4',
            'chin': 1, 'chout': 1, 'hidden': 48, 'depth': 4,
            'kernel_size': 8, 'stride': 4, 'causal': True,
            'resample': 4, 'growth': 1.5, 'max_hidden': 192,
            'normalize': True, 'glu': False, 'rescale': 0.1
        },
        
        # 4. ì›ë³¸ ê²½ëŸ‰ ëª¨ë¸ë“¤ (ë¹„êµìš©)
        {
            'name': 'Original-48-Depth5',
            'chin': 1, 'chout': 1, 'hidden': 48, 'depth': 5,
            'kernel_size': 8, 'stride': 4, 'causal': True,
            'resample': 4, 'growth': 2, 'max_hidden': 10000,
            'normalize': True, 'glu': True, 'rescale': 0.1
        },
        
        # 5. ë” ìž‘ì€ ì‹¤í—˜ì  ëª¨ë¸ë“¤
        {
            'name': 'Tiny-16',
            'chin': 1, 'chout': 1, 'hidden': 16, 'depth': 3,
            'kernel_size': 6, 'stride': 3, 'causal': True,
            'resample': 2, 'growth': 1.5, 'max_hidden': 64,
            'normalize': True, 'glu': False, 'rescale': 0.1
        },
        {
            'name': 'Micro-12',
            'chin': 1, 'chout': 1, 'hidden': 12, 'depth': 2,
            'kernel_size': 6, 'stride': 3, 'causal': True,
            'resample': 2, 'growth': 1.5, 'max_hidden': 48,
            'normalize': True, 'glu': False, 'rescale': 0.1
        }
    ]
    
    results = []
    
    for i, config in enumerate(model_configs):
        config_copy = config.copy()
        model_name = config_copy.pop('name')
        
        print(f"[{i+1}/{len(model_configs)}] í…ŒìŠ¤íŠ¸ ì¤‘: {model_name}")
        print(f"  ì„¤ì •: hidden={config_copy['hidden']}, depth={config_copy['depth']}, "
              f"resample={config_copy['resample']}, growth={config_copy['growth']}")
        
        result = test_model_rtf(config_copy, num_tests=3, audio_duration=4.0)
        result['name'] = model_name
        results.append(result)
        
        if result['success']:
            print(f"  âœ… ì„±ê³µ: RTF={result['avg_rtf']:.3f}, "
                  f"ëª¨ë¸ í¬ê¸°={result['model_size_mb']:.1f}MB")
            if result['avg_rtf'] < 1.0:
                print(f"     ðŸŽ¯ RTF < 1.0 ë‹¬ì„±!")
        else:
            print(f"  âŒ ì‹¤íŒ¨: {result['error']}")
        print()
    
    # ê²°ê³¼ ì •ë¦¬ ë° ì¶œë ¥
    print("=" * 80)
    print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    
    # ì„±ê³µí•œ ëª¨ë¸ë“¤ë§Œ í•„í„°ë§
    successful_results = [r for r in results if r['success']]
    
    if not successful_results:
        print("âŒ ì„±ê³µí•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # RTF ìˆœìœ¼ë¡œ ì •ë ¬
    successful_results.sort(key=lambda x: x['avg_rtf'])
    
    print(f"{'ìˆœìœ„':<4} {'ëª¨ë¸ëª…':<20} {'RTF':<8} {'í¬ê¸°(MB)':<10} {'ìƒíƒœ'}")
    print("-" * 60)
    
    rtf_under_1_models = []
    
    for i, result in enumerate(successful_results):
        status = "ðŸŽ¯ ëª©í‘œë‹¬ì„±" if result['avg_rtf'] < 1.0 else "âš ï¸  ëª©í‘œë¯¸ë‹¬"
        if result['avg_rtf'] < 1.0:
            rtf_under_1_models.append(result)
        
        print(f"{i+1:<4} {result['name']:<20} {result['avg_rtf']:<8.3f} "
              f"{result['model_size_mb']:<10.1f} {status}")
    
    print()
    
    if rtf_under_1_models:
        print("ðŸŽ¯ RTF < 1.0 ë‹¬ì„± ëª¨ë¸ë“¤:")
        print("-" * 40)
        for model in rtf_under_1_models:
            print(f"  â€¢ {model['name']}: RTF={model['avg_rtf']:.3f}, "
                  f"í¬ê¸°={model['model_size_mb']:.1f}MB")
            print(f"    ì„¤ì •: {model['config']}")
        
        best_model = rtf_under_1_models[0]
        print(f"\nðŸ† ìµœì  ëª¨ë¸: {best_model['name']}")
        print(f"   RTF: {best_model['avg_rtf']:.3f}")
        print(f"   ëª¨ë¸ í¬ê¸°: {best_model['model_size_mb']:.1f}MB")
        print(f"   ì„¤ì •: {best_model['config']}")
    else:
        print("âŒ RTF < 1.0ì„ ë‹¬ì„±í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ê°€ìž¥ ë¹ ë¥¸ ëª¨ë¸:")
        best = successful_results[0]
        print(f"  {best['name']}: RTF={best['avg_rtf']:.3f}")
    
    # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ìž¥
    results_file = Path('/home/test1/denoiser/rtf_test_results.txt')
    with open(results_file, 'w') as f:
        f.write("ë¼ì¦ˆë² ë¦¬íŒŒì´ 5 RTF í…ŒìŠ¤íŠ¸ ê²°ê³¼\n")
        f.write("=" * 50 + "\n\n")
        
        for result in successful_results:
            f.write(f"ëª¨ë¸: {result['name']}\n")
            f.write(f"RTF: {result['avg_rtf']:.3f}\n")
            f.write(f"ëª¨ë¸ í¬ê¸°: {result['model_size_mb']:.1f}MB\n")
            f.write(f"ì„¤ì •: {result['config']}\n")
            f.write("-" * 30 + "\n")
    
    print(f"\nðŸ“„ ìƒì„¸ ê²°ê³¼ê°€ {results_file}ì— ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
